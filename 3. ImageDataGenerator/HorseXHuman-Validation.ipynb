{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read image\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow is using GPU.\n"
     ]
    }
   ],
   "source": [
    "# Get the list of available GPUs\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "# Print the list of available GPUs\n",
    "print(\"Available GPUs:\", gpu_devices)\n",
    "\n",
    "# Check if TensorFlow is using GPU\n",
    "if gpu_devices:\n",
    "    print(\"TensorFlow is using GPU.\")\n",
    "    # Specify which GPU to use (assuming you have at least one GPU)\n",
    "    tf.config.experimental.set_visible_devices(gpu_devices[0], 'GPU')\n",
    "else:\n",
    "    print(\"TensorFlow is NOT using GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use wget  to download data\n",
    "\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_url = \"https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\"\n",
    "validation_url = \"https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip\"\n",
    "\n",
    "# download\n",
    "# wget.download(training_url, out=\"training.zip\")\n",
    "# wget.download(validation_url, out=\"validation.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# unzip training\n",
    "local_zip = \"./training.zip\"\n",
    "zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
    "zip_ref.extractall(\"./training\")\n",
    "\n",
    "# unzip training\n",
    "local_zip = \"./validation.zip\"\n",
    "zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
    "zip_ref.extractall(\"./validation\")\n",
    "\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# train horse directory\n",
    "train_horse_dir = os.path.join(\"./training/horses/\")\n",
    "\n",
    "# train human dir\n",
    "train_human_dir = os.path.join(\"./training/humans/\")\n",
    "\n",
    "# val horse dir\n",
    "val_horse_dir = os.path.join(\"./validation/horses/\")\n",
    "\n",
    "# val human dir\n",
    "val_human_dir = os.path.join(\"./validation/humans/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train horses : 500\n",
      "Number of train humans : 527\n",
      "Number of val horses : 128\n",
      "Number of val humans : 128\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of train horses : {len(os.listdir(train_horse_dir))}\")\n",
    "print(f\"Number of train humans : {len(os.listdir(train_human_dir))}\")\n",
    "print(f\"Number of val horses : {len(os.listdir(val_horse_dir))}\")\n",
    "print(f\"Number of val humans : {len(os.listdir(val_human_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 149, 149, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,704,097\n",
      "Trainable params: 1,704,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # 1st convolutional layer\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # 2nd convolutional layer\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # 3rd convolutional layer\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # 4th convolutional layer\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # 5th convolutional layer\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# import image generator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# scaling\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# flow training images using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"./training/\",\n",
    "    target_size=(300, 300),\n",
    "    batch_size=64,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "# flow validation images\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    \"./validation/\",\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8/8 [==============================] - 27s 2s/step - loss: 0.7617 - accuracy: 0.4844 - val_loss: 0.6421 - val_accuracy: 0.5469\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 7s 853ms/step - loss: 0.7965 - accuracy: 0.6680 - val_loss: 0.5539 - val_accuracy: 0.8789\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 6s 759ms/step - loss: 0.4683 - accuracy: 0.8184 - val_loss: 0.7294 - val_accuracy: 0.7930\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 5s 663ms/step - loss: 0.6489 - accuracy: 0.7949 - val_loss: 0.4041 - val_accuracy: 0.8555\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 6s 710ms/step - loss: 0.2853 - accuracy: 0.8965 - val_loss: 1.1051 - val_accuracy: 0.8125\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 6s 708ms/step - loss: 0.1899 - accuracy: 0.9297 - val_loss: 1.4165 - val_accuracy: 0.8086\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 5s 655ms/step - loss: 0.1208 - accuracy: 0.9512 - val_loss: 1.2035 - val_accuracy: 0.8516\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 5s 633ms/step - loss: 0.1652 - accuracy: 0.9379 - val_loss: 2.4096 - val_accuracy: 0.6953\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 6s 685ms/step - loss: 0.3444 - accuracy: 0.8965 - val_loss: 0.9333 - val_accuracy: 0.8633\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 5s 663ms/step - loss: 0.2648 - accuracy: 0.9336 - val_loss: 1.3089 - val_accuracy: 0.8047\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 5s 639ms/step - loss: 0.1318 - accuracy: 0.9512 - val_loss: 1.0655 - val_accuracy: 0.8633\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 5s 637ms/step - loss: 0.0439 - accuracy: 0.9863 - val_loss: 1.0429 - val_accuracy: 0.8711\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 5s 650ms/step - loss: 0.1166 - accuracy: 0.9688 - val_loss: 0.4285 - val_accuracy: 0.9102\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 5s 580ms/step - loss: 0.3083 - accuracy: 0.9246 - val_loss: 0.6281 - val_accuracy: 0.8555\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 5s 614ms/step - loss: 0.1455 - accuracy: 0.9473 - val_loss: 1.3051 - val_accuracy: 0.8438\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=8,\n",
    "    epochs=15,\n",
    "    verbose=1,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
